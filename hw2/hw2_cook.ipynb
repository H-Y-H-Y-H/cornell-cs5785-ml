{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] N is 39774.\n",
      "Index([u'cuisine', u'id', u'ingredients'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read data and transform to X: N*P, y: N*1 format\n",
    "train_data = pd.read_json(\"train.json\")\n",
    "print \"[INFO] N is %d.\" % train_data.shape[0]\n",
    "print train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] In total 20 labels\n",
      "[u'brazilian' u'british' u'cajun_creole' u'chinese' u'filipino' u'french'\n",
      " u'greek' u'indian' u'irish' u'italian' u'jamaican' u'japanese' u'korean'\n",
      " u'mexican' u'moroccan' u'russian' u'southern_us' u'spanish' u'thai'\n",
      " u'vietnamese']\n"
     ]
    }
   ],
   "source": [
    "# handle labels (y)\n",
    "\n",
    "# TODO\n",
    "_labels = train_data.cuisine\n",
    "label_enc = LabelEncoder()\n",
    "y = label_enc.fit_transform(_labels)\n",
    "\n",
    "assert len(label_enc.classes_) == len(set(_labels))\n",
    "assert y.shape[0] == train_data.shape[0]\n",
    "print \"[INFO] In total %d labels\" % len(label_enc.classes_)\n",
    "\n",
    "print label_enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] In total 6714 ingredients.\n",
      "\n",
      "--show first sample--\n",
      "  (0, 956)\t1\n",
      "  (0, 2548)\t1\n",
      "  (0, 2878)\t1\n",
      "  (0, 2884)\t1\n",
      "  (0, 3033)\t1\n",
      "  (0, 4569)\t1\n",
      "  (0, 4911)\t1\n",
      "  (0, 5222)\t1\n",
      "  (0, 5405)\t1\n",
      "--\n",
      "CPU times: user 475 ms, sys: 20.3 ms, total: 495 ms\n",
      "Wall time: 503 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# handle ingredients (e.g. X[i, 0:p])\n",
    "\n",
    "# Q to TA : common operations on csr_matrix\n",
    "# Q to TA : code too ugly\n",
    "\n",
    "from itertools import chain\n",
    "all_igdt = set(chain.from_iterable(train_data.ingredients))\n",
    "print \"[INFO] In total %d ingredients.\" % len(all_igdt)\n",
    "        \n",
    "    \n",
    "_igdt_str_list = map(lambda r: \"sepearate\".join(r), train_data.ingredients)\n",
    "assert len(_igdt_str_list) == train_data.shape[0]\n",
    "\n",
    "# def tok(x):\n",
    "#     print \"[INFO] %s\" % x\n",
    "#     return x.split('sepearate')\n",
    "\n",
    "enc = CountVectorizer(vocabulary=all_igdt, \n",
    "                      tokenizer=lambda x : x.split('sepearate'))\n",
    "X = enc.fit_transform(_igdt_str_list)\n",
    "\n",
    "assert X.shape == (train_data.shape[0], len(all_igdt))\n",
    "print \"\\n--show first sample--\"\n",
    "print X[0,:]\n",
    "print \"--\"\n",
    "\n",
    "\n",
    "# print enc.get_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 6714) (39774,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.779107837119\n",
      "CPU times: user 5.59 s, sys: 2.03 ms, total: 5.6 s\n",
      "Wall time: 5.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LR\n",
    "cls_lr = LogisticRegression()\n",
    "cls_lr.fit(X[:30000], y[:30000])\n",
    "print cls_lr.score(X[30000:], y[30000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.370644139388\n",
      "CPU times: user 10.6 s, sys: 30min 13s, total: 30min 23s\n",
      "Wall time: 1h 22min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Q TA why cannot use csr matrix in Gaussian prior NB?\n",
    "\n",
    "# Naiive Bayes Classifier - Gaussian prior assumption\n",
    "# cls_gaussian_nb = GaussianNB()\n",
    "# cls_gaussian_nb.fit(X[:30000].toarray(), y[:30000])\n",
    "# print cls_gaussian_nb.score(X[30000:].toarray(), y[30000:])\n",
    "\n",
    "tr = []\n",
    "te = []\n",
    "for tr_idx, te_idx in cross_validation.KFold(X.shape[0], n_folds=3):\n",
    "    tr.append(tr_idx)\n",
    "    te.append(te_idx)\n",
    "cls_gaussian_nb = GaussianNB()\n",
    "cls_gaussian_nb.fit(X[tr[0]].toarray(), y[tr[0]])\n",
    "score = cls_gaussian_nb.score(X[te[0]].toarray(), y[te[0]])\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690300798036\n"
     ]
    }
   ],
   "source": [
    "# Naiive Bayes Classifier - Bernouli prior assumption\n",
    "cls_bernoulli_nb = BernoulliNB()\n",
    "cls_bernoulli_nb.fit(X[:30000], y[:30000])\n",
    "print cls_bernoulli_nb.score(X[30000:], y[30000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'id', u'ingredients'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Test phase\n",
    "test_data = pd.read_json('test.json')\n",
    "print test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_te = enc.transform(map(lambda r: \"sepearate\".join(r), test_data.ingredients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9944, 6714)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X_te.shape\n",
    "mdl = LogisticRegression()\n",
    "mdl.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_te = mdl.predict(X_te)\n",
    "labels_te = label_enc.inverse_transform(y_te)\n",
    "ret = np.column_stack((test_data.id, labels_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('testResult_cooking.csv', ret, delimiter=',', fmt='%s', header='id,cuisine', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18009\n",
      "1    28583\n",
      "2    41580\n",
      "3    29752\n",
      "4    35687\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset_selective X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable             Type               Data/Info\n",
      "-------------------------------------------------\n",
      "BernoulliNB          ABCMeta            <class 'sklearn.naive_bayes.BernoulliNB'>\n",
      "CountVectorizer      type               <class 'sklearn.feature_e<...>on.text.CountVectorizer'>\n",
      "GaussianNB           ABCMeta            <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "LabelEncoder         type               <class 'sklearn.preproces<...>sing.label.LabelEncoder'>\n",
      "LogisticRegression   type               <class 'sklearn.linear_mo<...>stic.LogisticRegression'>\n",
      "X                    csr_matrix           (0, 956)\t1\\n  (0, 2548)<...>309)\t1\\n  (39773, 6519)\t1\n",
      "all_igdt             set                set([u'low-sodium fat-fre<...>ef broth', u'hot water'])\n",
      "chain                type               <type 'itertools.chain'>\n",
      "cm                   module             <module 'matplotlib.cm' f<...>kages/matplotlib/cm.pyc'>\n",
      "cross_validation     module             <module 'sklearn.cross_va<...>rn/cross_validation.pyc'>\n",
      "enc                  CountVectorizer    CountVectorizer(analyzer=<...>f broth', u'hot water']))\n",
      "label_enc            LabelEncoder       LabelEncoder()\n",
      "np                   module             <module 'numpy' from '/ho<...>ages/numpy/__init__.pyc'>\n",
      "pd                   module             <module 'pandas' from '/h<...>ges/pandas/__init__.pyc'>\n",
      "plt                  module             <module 'matplotlib.pyplo<...>s/matplotlib/pyplot.pyc'>\n",
      "train_data           DataFrame                      cuisine     i<...>n[39774 rows x 3 columns]\n",
      "y                    ndarray            39774: 39774 elems, type `int64`, 318192 bytes (310 kb)\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
